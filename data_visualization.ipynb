{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from saxs.data_generation.processing import Processing\n",
    "from saxs.data_generation.data_visualization import load_data, plot_saxs, plot_saxs_featuremap\n",
    "from saxs.data_generation.generation import Generator\n",
    "from saxs.data_generation import DEFAULT_CONFIG_PATH\n",
    "\n",
    "import json\n",
    "\n",
    "from saxs.gaussian_processing.processing_outils import read_data\n",
    "\n",
    "with open(DEFAULT_CONFIG_PATH) as config:\n",
    "    config_data = json.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q, d1 = load_data(phase=config_data['phase'],\n",
    "                                cubic_mesophase=config_data['cubic_mesophase'],\n",
    "                                )\n",
    "q = q[:498]\n",
    "q_0, I_0, dI = read_data('/Users/isaigordeev/Desktop/2023/saxs/res/075775_treated_xye.csv')\n",
    "I_0 = I_0[:498]\n",
    "q_0 = q_0[:498]\n",
    "mean = np.mean(I_0)\n",
    "var = np.std(I_0)\n",
    "I_0 -= mean\n",
    "I_0 /= (var ** 0.5)\n",
    "I_0 /= np.max(I_0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for n in random.sample(range(len(d1)), 10):\n",
    "    # plot_saxs(q , d1[n])\n",
    "    plt.plot(q, d1[n]/np.max(d1[n]))\n",
    "    plt.plot(q_0, I_0/np.max(I_0), 'red')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = np.uint8(d1[0]*255)\n",
    "plt.imshow(np.repeat(np.expand_dims(np.outer(image, image), -1), 3, axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = np.uint8(I_0/np.max(I_0)*255)\n",
    "plt.imshow(np.repeat(np.expand_dims(np.outer(image, image), -1), 3, axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for n in random.sample(range(len(d1)), 10):\n",
    "    # plot_saxs(q , d1[n])\n",
    "    plt.plot(q, d1[n]/np.max(d1[n]))\n",
    "    plt.plot(q_0, I_0/np.max(I_0), 'red')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = np.uint8(d1[0]*255)\n",
    "plt.imshow(np.repeat(np.expand_dims(np.outer(image, image), -1), 3, axis=-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(d1[0][68:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "PatchEmbedding(\n",
      "  (patcher): Conv2d(3, 228, kernel_size=(14, 14), stride=(14, 14))\n",
      "  (flatten): Flatten(start_dim=2, end_dim=3)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "========================================================================================================================\nLayer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n========================================================================================================================\nSAXSViT10 (SAXSViT10)                    [1, 3, 448, 448]     [1, 3]               233,928              True\n├─PatchEmbedding (patch_embedding)       [1, 3, 448, 448]     [1, 1024, 228]       --                   True\n│    └─Conv2d (patcher)                  [1, 3, 448, 448]     [1, 228, 32, 32]     134,292              True\n│    └─Flatten (flatten)                 [1, 228, 32, 32]     [1, 228, 1024]       --                   --\n├─Dropout (embedding_dropout)            [1, 1025, 228]       [1, 1025, 228]       --                   --\n├─Sequential (transformer_encoder)       [1, 1025, 228]       [1, 1025, 228]       --                   True\n│    └─TransformerEncoderLayer (0)       [1, 1025, 228]       [1, 1025, 228]       1,613,892            True\n│    └─TransformerEncoderLayer (1)       [1, 1025, 228]       [1, 1025, 228]       1,613,892            True\n│    └─TransformerEncoderLayer (2)       [1, 1025, 228]       [1, 1025, 228]       1,613,892            True\n├─Sequential (classifier)                [1, 228]             [1, 3]               --                   True\n│    └─LayerNorm (0)                     [1, 228]             [1, 228]             456                  True\n│    └─Linear (1)                        [1, 228]             [1, 228]             52,212               True\n│    └─GELU (2)                          [1, 228]             [1, 228]             --                   --\n│    └─Linear (3)                        [1, 228]             [1, 3]               687                  True\n========================================================================================================================\nTotal params: 5,263,251\nTrainable params: 5,263,251\nNon-trainable params: 0\nTotal mult-adds (M): 137.57\n========================================================================================================================\nInput size (MB): 2.41\nForward/backward pass size (MB): 1.87\nParams size (MB): 0.75\nEstimated Total Size (MB): 5.03\n========================================================================================================================"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from saxs.saxs_model.model import SAXSViT10\n",
    "\n",
    "from torchinfo import summary #optional\n",
    "\n",
    "from saxs.saxs_model.model_settings import IMAGE_DIM, COLOR_CHANNELS, PATCH_SIZE, ATTENTION_BLOCKS, EMBEDDING_DIM\n",
    "\n",
    "mod = SAXSViT10(448,\n",
    "                COLOR_CHANNELS,\n",
    "                14,\n",
    "                3,\n",
    "                228,\n",
    "                3072, 12, 0.1, 0, 0.1, 3)\n",
    "\n",
    "print(mod.patch_embedding)\n",
    "\n",
    "\n",
    "summary(mod,\n",
    "        input_size=(1, 3, IMAGE_DIM, IMAGE_DIM),  # (batch_size, color_channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from saxs import PACKAGE_PATH, DEFAULT_PHASES_PATH\n",
    "from saxs.saxs_model.model import SAXSViT10\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import saxs.saxs_model.saxs_dataset as data_setup\n",
    "from saxs import PACKAGE_PATH\n",
    "import json\n",
    "import saxs.saxs_model.phase_prediction as phase_prediction\n",
    "from saxs.saxs_model import engine\n",
    "from saxs.saxs_model.model import SAXSViT\n",
    "from saxs.saxs_model.model_settings import DEVICE\n",
    "\n",
    "from torchinfo import summary #optional\n",
    "\n",
    "from saxs.saxs_model.model_settings import IMAGE_DIM, COLOR_CHANNELS, PATCH_SIZE, ATTENTION_BLOCKS, EMBEDDING_DIM\n",
    "\n",
    "with open(DEFAULT_PHASES_PATH, 'r') as file:  # NOTE make it better with string formatting\n",
    "    phases = json.load(file)\n",
    "\n",
    "classes = list(phases.keys())\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "\n",
    "mod = SAXSViT10(IMAGE_DIM,\n",
    "                COLOR_CHANNELS,\n",
    "                166,\n",
    "                3,\n",
    "                24,\n",
    "                3072, 12, 0.1, 0, 0.1, 3)\n",
    "\n",
    "train_saxs_batches, test_saxs_batches, saxs_phases = \\\n",
    "    data_setup.create_data_batches_from_dataset_files(path=os.path.join(PACKAGE_PATH, 'cache'),\n",
    "                                                    transforms=None,\n",
    "                                                    batch_size=32,\n",
    "                                                    num_workers=0\n",
    "                                                     )\n",
    "\n",
    "# optimizer = torch.optim.Adam(params=mod.parameters(),\n",
    "#                              lr=1e-3)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#\n",
    "# pretrained_vit_results = engine.train(model=mod,\n",
    "#                                       train_dataloader=train_saxs_batches,\n",
    "#                                       test_dataloader=test_saxs_batches,\n",
    "#                                       optimizer=optimizer,\n",
    "#                                       loss_fn=loss_fn,\n",
    "#                                       epochs=1,\n",
    "#                                       device=DEVICE)\n",
    "\n",
    "\n",
    "phase_prediction.prediction_from_npy(mod,\n",
    "                            'res/075773_treated_xye.csv',\n",
    "                            classes,\n",
    "                            )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import saxs.saxs_model.phase_prediction as prediction_from_csv\n",
    "from saxs.saxs_model.model import SAXSViT10\n",
    "import torch\n",
    "\n",
    "model = SAXSViT10(498,\n",
    "                3,\n",
    "                166,\n",
    "                3,\n",
    "                96,\n",
    "                3072, 12, 0.1, 0, 0.1, 3)\n",
    "\n",
    "state_dict = torch.load('model0.pth')\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "prediction_from_csv(model, 'res/075773_treated_xye.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "\n",
    "vit_pretrained = torchvision.models.vit_b_16(pretrained_vit_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x146412040>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "============================================================================================================================================\nLayer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n============================================================================================================================================\nVisionTransformer (VisionTransformer)                        [1, 3, 224, 224]     [1, 1000]            768                  True\n├─Conv2d (conv_proj)                                         [1, 3, 224, 224]     [1, 768, 14, 14]     590,592              True\n├─Encoder (encoder)                                          [1, 197, 768]        [1, 197, 768]        151,296              True\n│    └─Dropout (dropout)                                     [1, 197, 768]        [1, 197, 768]        --                   --\n│    └─Sequential (layers)                                   [1, 197, 768]        [1, 197, 768]        --                   True\n│    │    └─EncoderBlock (encoder_layer_0)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_1)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_2)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_3)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_4)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_5)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_6)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_7)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_8)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_9)                   [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_10)                  [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    │    └─EncoderBlock (encoder_layer_11)                  [1, 197, 768]        [1, 197, 768]        7,087,872            True\n│    └─LayerNorm (ln)                                        [1, 197, 768]        [1, 197, 768]        1,536                True\n├─Sequential (heads)                                         [1, 768]             [1, 1000]            --                   True\n│    └─Linear (head)                                         [1, 768]             [1, 1000]            769,000              True\n============================================================================================================================================\nTotal params: 86,567,656\nTrainable params: 86,567,656\nNon-trainable params: 0\nTotal mult-adds (M): 173.23\n============================================================================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 104.09\nParams size (MB): 232.27\nEstimated Total Size (MB): 336.96\n============================================================================================================================================"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summary(vit_pretrained,\n",
    "        input_size=(1, 3, 224, 224),  # (batch_size, color_channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
